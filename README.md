## A record of my paper reading

#### 2018-10

The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation [[Arxiv](http://arxiv.org/abs/1804.09849)]

TRANSFORMER-XL: LANGUAGE MODELING WITH LONGER-TERM DEPENDENCY []

Deep contextualized word representations [[Arxiv](https://arxiv.org/abs/1802.05365)]

What you can cram into a single $&!#* vector: Probing sentence embeddings for linguistic properties [[Arxiv](https://arxiv.org/abs/1805.01070)]

#### 2018-09

Evaluation of sentence embeddings in downstream and linguistic probing tasks [[Arxiv](https://arxiv.org/abs/1806.06259)]

[An efficient framework for learning sentence representations](https://arxiv.org/abs/1803.02893)

Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning [[Arxiv](https://arxiv.org/abs/1804.00079)]

Universal Sentence Encoder [[Arxiv](https://arxiv.org/pdf/1803.11175.pdf)]

Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures [[Arxiv](https://arxiv.org/abs/1808.08946)]

A Study of Reinforcement Learning for Neural Machine Translation [[Arxiv](https://arxiv.org/abs/1808.08866)]

